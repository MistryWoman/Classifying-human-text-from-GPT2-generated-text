{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "dataset_download_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BCEomkaNvZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3026a6d7-53b2-4c26-d204-5ed07f06ea2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g98lu3jZrwu",
        "colab_type": "code",
        "outputId": "e7fe5b1b-06bc-4f3f-d84d-652e6642aebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import Field, LabelField\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import Iterator, BucketIterator\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "import json\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "from spacy.pipeline import SentenceSegmenter\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruUiVAYUfE1n",
        "colab_type": "code",
        "outputId": "30e7a0c1-58ba-4161-9766-35246618f92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "! pip install -U nltk\n",
        "corpus_bleu([[['are', 'you', 'going', 'to', 'enter', 'the', 'competition', '?']]], \n",
        "            [['i', 'i', 'the', 'the', 'the', 'the', '.', '.', '.', '.', '.', '.']], \n",
        "            weights=(0.25, 0.25, 0.25, 0.25))  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.5)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.788429383461836e-232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWFPXIiZVeW",
        "colab_type": "code",
        "outputId": "43c50ef9-b4c8-4987-b370-5750ce6f9a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Set seed of randomization and working device\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5xrVIJJjmd7",
        "colab_type": "text"
      },
      "source": [
        "#Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUX9CLaFZH4k",
        "colab_type": "code",
        "outputId": "e7bbe2f2-9cba-42b5-8a41-966de372decf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# subdir = 'data'\n",
        "# if not os.path.exists(subdir):\n",
        "#     os.makedirs(subdir)\n",
        "# subdir = subdir.replace('\\\\','/') # needed for Windows\n",
        "\n",
        "# for ds in [\n",
        "#     'webtext',\n",
        "# #     'small-117M',  'small-117M-k40',\n",
        "# #     'medium-345M', 'medium-345M-k40',\n",
        "# #     'large-762M',  'large-762M-k40',\n",
        "#     'xl-1542M',    'xl-1542M-k40',\n",
        "# ]:\n",
        "#     for split in ['train', 'valid', 'test']:\n",
        "#         filename = ds + \".\" + split + '.jsonl'\n",
        "#         r = requests.get(\"https://storage.googleapis.com/gpt-2/output-dataset/v1/\" + filename, stream=True)\n",
        "\n",
        "#         with open(os.path.join(subdir, filename), 'wb') as f:\n",
        "#             file_size = int(r.headers[\"content-length\"])\n",
        "#             chunk_size = 1000\n",
        "#             with tqdm(ncols=100, desc=\"Fetching \" + filename, total=file_size, unit_scale=True) as pbar:\n",
        "#                 # 1k for chunk_size, since Ethernet packet size is around 1500 bytes\n",
        "#                 for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "#                     f.write(chunk)\n",
        "#                     pbar.update(chunk_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching webtext.train.jsonl: 679Mit [00:09, 70.0Mit/s]                                             \n",
            "Fetching webtext.valid.jsonl: 13.6Mit [00:00, 41.7Mit/s]                                            \n",
            "Fetching webtext.test.jsonl: 13.5Mit [00:00, 37.8Mit/s]                                             \n",
            "Fetching xl-1542M.train.jsonl: 724Mit [00:12, 59.8Mit/s]                                            \n",
            "Fetching xl-1542M.valid.jsonl: 14.4Mit [00:01, 9.29Mit/s]                                           \n",
            "Fetching xl-1542M.test.jsonl: 14.6Mit [00:00, 56.9Mit/s]                                            \n",
            "Fetching xl-1542M-k40.train.jsonl: 748Mit [00:09, 77.5Mit/s]                                        \n",
            "Fetching xl-1542M-k40.valid.jsonl: 15.0Mit [00:00, 54.4Mit/s]                                       \n",
            "Fetching xl-1542M-k40.test.jsonl: 14.6Mit [00:00, 64.5Mit/s]                                        \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38xNxJc_ZUX9",
        "colab_type": "code",
        "outputId": "247c55f6-fc5b-4fcd-bf88-8e629c364b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# code to explore data\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/data/\"\n",
        "\n",
        "def _load_split(data_dir, source, split, n=np.inf):\n",
        "    path = os.path.join(data_dir, f'{source}.{split}.jsonl')\n",
        "    texts = []\n",
        "    for i, line in enumerate(open(path)):\n",
        "        if i >= n:\n",
        "            break\n",
        "        texts.append(json.loads(line)['text'])\n",
        "    return texts\n",
        "\n",
        "text = _load_split(data_dir, \"webtext\", split=\"train\")\n",
        "\n",
        "text[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"These girlfriends deserves a special mention for going that extra mile, hopefully doesn't set too many guys off on the path towards outrageous demands.\\n\\n1. She knows the severity of man-flu\\n\\n2. All fun and games is all good\\n\\n3. A voucher that says 'I love you'\\n\\n4. When arguments don't drag on forever.\\n\\n5. Providing everything he needs.\\n\\n6. Very understanding\\n\\n7. As awesome a gesture as this is, we are worried about this man's cooking skills.\\n\\n8. Nice cake\\n\\n8. Fair bargaining\\n\\n9. Excellent gift choice\\n\\n10. Very thoughtful\",\n",
              " 'LeSean McCoy going through warmups with first team offense. To my eye, does not look close to 100 percent when cutting and exploding.\\n\\nABOUT COOKIES\\n\\nTo help make this website better, to improve and personalize your experience and for advertising purposes, are you happy to accept cookies and other technologies?',\n",
              " \"Tom Curran has been called up to England's Ashes squad. The 22-year-old Surrey all-rounder will fly out to Australia in the next 24 hours as a replacement for Steven Finn, after the Middlesex fast bowler was ruled out of the rest of the tour with a torn left knee cartilage.\\n\\nCurran is yet to play a Test match for England. However, he broke into the white-ball side during the 2017 season, making his debut in Twenty20 and one-day international cricket, and impressed the England management with his attitude.\\n\\nCoach Trevor Bayliss is known to be a fan, and so Curran has been preferred to the likes of Liam Plunkett, Tom Helm, George Garton and Mark Wood as England seek to bolster their ailing pace-bowling reserves ahead of the toughest series of them all.\\n\\nShape Created with Sketch. England Ashes squad Show all 17 left Created with Sketch. right Created with Sketch. Shape Created with Sketch. England Ashes squad 1/17 Captain: Joe Root England's Mr Dependable will lead his side into an Ashes series for the first time, and while he has the experience of the series wins in 2013 and 2015, he also has the scars of the last trip Down Under. Getty 2/17 Batsman: Alastair Cook The former captain will be crucial to England's hopes, with the Essex opener needing to find the same resilient form that he displayed in Australia in the 2010/11 series. Getty 3/17 Batsman: Mark Stoneman Cook's likely opening partner will be Mark Stoneman after selectors decided to stick with him despite a nervous series against the West Indies. Getty 4/17 Batsman/spinner: Dawid Malan Malan showed glimpses of promise this summer and can also offer an option with the ball, but he is untested on the hard pitches of Australia and could be found out. Getty 5/17 Batsman: Gary Ballance Ballance is handed yet another chance to salvage his England career as the selectors hope he will eventually come good for their unyielding faith. Getty 6/17 Batsman: James Vince Vince is the surprise inclusion in the squad, having done little of note in county cricket since being dropped in 2016. Getty 7/17 Batsman/spinner: Moeen Ali Moeen Ali could easily go on to be man of the series given his ability to deliver fireworks with bat and ball. He may disagree, but he is undoubtedly England's front line spinner. Getty 8/17 Batsman/spinner: Mason Crane Crane is yet to make his full debut, though took a wonderful catch against the West Indies as a substitute fielder and will head to Australia as a back-up leg-break spiner bowler. Getty 9/17 Wicketkeeper: Ben Foakes Foakes will head to Australia as a deputy for first-choice wicketkeeper Jonny Bairstow. Getty 10/17 Wicketkeeper: Jonny Bairstow Another man who will need to produce runs to give England a chance of victory, with his ability in the mid-order giving the tourists a bite throughout the line-up. Getty 11/17 All-rounder: Ben Stokes Stokes is named in the side despite falling under a huge cloud after his arrest on a late night out in Bristol. His future as vice-captain looks very much in doubt. Getty 12/17 All-rounder: Chris Woakes Woakes will provide rest for the front-line bowlers and will also prove handy with the bat. Getty 13/17 Bowler: Stuart Broad Broad has long set his sights on this Ashes tour as he hopes to make up for the 2013/14 humiliation, and his opening partnership with James Anderson will set the tone for how England will cope out in Australia. Getty 14/17 Bowler: James Anderson England's leading Test wicket-taker will be wrapped in cotton wool until the first Test, though he will have to deliver the goods in a country where swing can be hard to find. Getty 15/17 Bowler: Jake Ball Ball could prove to be England's joke in the pack given his extra pace and bounce. Think Chris Tremlett a la 2010/11. It's just a case of keeping him fit. Getty 16/17 Bowler: Craig Overton The third uncapped member of the squad, Overton has been rewarded for a solid season with Somerset. Getty 17/17 Bowler: Tom Curran Called up by England to replace Steven Finn, who had previously been called up due to Ben Stokes' uncertainty. Getty 1/17 Captain: Joe Root England's Mr Dependable will lead his side into an Ashes series for the first time, and while he has the experience of the series wins in 2013 and 2015, he also has the scars of the last trip Down Under. Getty 2/17 Batsman: Alastair Cook The former captain will be crucial to England's hopes, with the\",\n",
              " 'We\\'ll have turkey on the table Thursday but, as yet, it looks like no turkey in the Presidential on-deck circle. And both Gov. Howard Dean and Congressman Bernie Sanders think credit should go where credit is due. That means, thank you, Ralph Nader. Thanks a whole frickin\\' lot!\\n\\nShortly after the votes were counted and the stalemate began, Dean said he hoped the Nader voters in the Sunshine State — all 93,000 — were \"happy.\" Said he hoped they would be comfortable with the Supreme Court justices that Dubya will be appointing if he proves to be the eventual winner. Dean supported Ralph Nader\\'s right to run, but sarcastically expressed the hope that Nader\\'s supporters will live at peace with themselves under the looming Bush administration.\\n\\nAnd Sanders, an old friend of the Green Party candidate, was even more upset.\\n\\n\"It seemed to me,\" said Ol\\' Bernardo, \"that in the last month or two, Nader really made a deliberate effort to defeat Al Gore. He went to those states where the races were closest and was pretty clear about his goal. I don\\'t understand that and I think that was wrong.\"\\n\\nHindsight\\'s always 20-20.\\n\\nThanks, Ralph.\\n\\nCivil-Unions Update — The 11-member commission established by Act 91 met last week at the Statehouse to check up on how Vermont\\'s landmark legalization of love for all couples was shaking out. The news was quite good.\\n\\nSteve Patterson, deputy commerce secretary, reported no negative repercussions whatsoever to date. While there\\'s plenty of anecdotal information about the positive effect the more than 1200 civil unions have had on Vermont\\'s hospitality sector, Patterson said his agency had compiled no data to quantify that.\\n\\nTown Clerk Linda Spence of Manchester told the commission over the speakerphone that implementation of the civil-unions law has been remarkably smooth. Vance is also a justice of the peace and the president of the Association of Town Clerks and Treasurers. She was familiar with just one case of rude treatment given an out-of-state lesbian couple by a town official in Weston.\\n\\n\"The sun still rises and sets in Vermont,\" said Spence. \"I myself am a heterosexual, but I have to say my experiences both as town clerk and justice of the peace have been nothing but positive with this law in place. It has proved to me to be one of the most moving and emotional pieces of legislation I have seen, and I don\\'t see where it does any harm to anybody.\"\\n\\nWe\\'re No.1??? — University of Vermont men\\'s ice hockey Coach Mike Gilligan told Seven Days Tuesday morning he\\'s hanging in there. After all, the guy\\'s a veteran of the game. A senior statesman. An institution.\\n\\nWhen Gilligan first hit Burlington, Bernie Sanders was mayor, Madeleine Kunin just got elected governor, Phish was a typo. Nobody ever heard of Bill Clinton. The lakefront bikepath did not exist.\\n\\nThings change.\\n\\nThat\\'s why we had to check Gilligan\\'s pulse this week. At no time in his 16 years of whistling Vermont line changes has Mike Gilligan been here before. It\\'s uncharted territory. The numbers don\\'t lie. As the old Green & Gold prepared for Tuesday night\\'s game against non-league opponent UMass-Amherst, Vermont is 4-0 and flying solo in first place in the ECAC.\\n\\nYeah, yeah, yeah, I know. It\\'s much too early to suggest that Cinderella is spending the winter in Burlington, Vermont. Way too early. Dream on, right?\\n\\nBut they say the darkest hour comes right before the dawn. And everybody remembers the black night that swallowed UVM last season. However, what these guys have been doing on the ice speaks volumes.\\n\\n\"They learned quite a bit last season,\" Gilligan told Seven Days. \"They learned how precious one game is. How precious a night on the ice is.\"\\n\\nIt shows.\\n\\nAnd make no mistake, this is a disciplined team in more ways than one. Gilligan told us forward Graham Mink, a junior from Stowe, Vermont, sat out the first four games as punishment for breaking an undisclosed team rule. When he finally got to play in the Yale game, Big Mink played like a gorilla on ice skates.\\n\\nA couple of Minnesota schools are coming in this weekend for a Saturday-Sunday tournament at the Gut with Gilligan\\'s Gorillas and UNH. Duluth and Mankato, in the giant Minnesota state university system, will hit Burlap with some rock-\\'em-sock-\\'em \"western-style\" hockey. Welcome to Vermont, boys!\\n\\nMedia Notes — Is there Mardi Gras coverage in Sera Congi\\'s future?\\n\\nCongi is the talented co-anchor of \"Vermont\\'s Own\" Ch. 3',\n",
              " 'The 1945 Sinkings of the Cap Arcona and the Thielbek\\n\\nAllied Attacks Killed Thousands of Concentration Camp Inmates\\n\\nBy Mark Weber\\n\\nAll prisoners of German wartime concentration camps who perished while in German custody are routinely regarded as \"victims of Nazism\" -- even if they lost their lives as direct or indirect result of Allied policy. Similarly, all Jews who died in German captivity during World War II -- no matter what the cause of death -- are counted as \"victims of the Holocaust.\"\\n\\nThis view is very misleading, if not deceitful. In fact, many tens of thousands of camp inmates and Jews lost their lives as direct and indirect victims of Allied action, or of the horrors of the Second World War. For example, the many thousands of Jews who perished in the notorious Bergen-Belsen camp during and after the final months of the war in Europe, including Anne Frank, were primarily victims not of German policy, but rather of the turmoil and chaos of war.\\n\\nAmong the German concentration camp prisoners who perished at Allied hands were some 7,000 inmates who were killed during the war\\'s final week as they were being evacuated in three large German ships that were attacked by British war planes. This little-known tragedy is one of history\\'s greatest maritime disasters.\\n\\nThe Cap Arcona, launched in May 1927, was a handsome passenger ship of the \"Hamburg-South America\" line. At 27,000 gross registered tons, it was the fourth-largest ship in the German merchant marine. For twelve years -- until the outbreak of war in 1939 -- she had sailed regularly between Hamburg and Rio de Janeiro. In the war\\'s final months she was pressed into service by the German navy to rescue refugees fleeing from areas in the east threatened by the Red Army. This was part of a vast rescue operation organized by the German navy under the supervision of Grand Admiral Karl Dönitz. All but unknown in the United States today, this great undertaking saved countless lives. The Thielbek, a much smaller ship of 2,800 gross registered tons, was also used to transport refugees as part of the rescue operation.\\n\\nIn April 1945, Karl Kaufmann, Gauleiter of Hamburg and Reich Commissioner for merchant shipping, transferred the Cap Arcona and the Thielbek from naval command, and ordered them to Neustadt Bay in the Baltic Sea near the north German city of Lübeck.\\n\\nSome 5,000 prisoners hastily evacuated from the Neuengamme concentration camp (a few miles southeast of Hamburg) were brought on board the Cap Arcona between April 18 and 26, along with some 400 SS guards, a naval gunnery detail of 500, and a crew of 76. Similarly the Thielbek took on some 2,800 Neuengamme prisoners. Under the terrible conditions that prevailed in what remained of unoccupied Germany during those final weeks, conditions for the prisoners on board the two vessels were dreadful. Many of the tightly packed inmates were ill, and both food and water were in very short supply.\\n\\nOn the afternoon of May 3, 1945, British \"Typhoon\" fighter-bombers, striking in several attack waves, bombarded and fired on the Cap Arcona and then the Thielbek. The two ships, which had no military function or mission, were flying many large white flags. \"The hoisting of white flags proved useless,\" notes the Encyclopedia of the Third Reich. The attacks were thus violations of international law, for which -- if Britain and not Germany had been the vanquished power -- British pilots and their commanders could have been punished and even executed as \"war criminals.\"\\n\\nThe Thielbek, struck by rockets, bombs and machine gun fire, sank in just 15-20 minutes. British planes then fired on terror-stricken survivors who were struggling in rescue boats or thrashing in the cold sea. Nearly everyone on board the Thielbek perished quickly, including nearly all the SS guards, ship\\'s officers and crew members. Only about 50 of the prisoners survived.\\n\\nThe burning Cap Arcona took longer to go under. Many inmates burned to death. Most of those who were able to leap overboard drowned in the cold sea, and only some 350-500 could be rescued. During the next several days hundreds of corpses washed up on nearby shores, and were buried in mass graves. Having sunk in shallow water, the wreck of the capsized Cap Arcona remained partially above water as a grim reminder of the catastrophe.\\n\\nA German reference work, Verheimlichte Dokumente, sums up:\\n\\nA particularly barbaric Allied war crime was the bombing on May 3, 1945, by British Royal Air Force planes of the passenger ships Cap Arcona and Thielbek in the Lübeck bay, packed with concentration camp inmates. Among the many \\'nameless\\' victims were many prominent political figures, a fact that is hushed up today because the fact that concentration camp inmates, many of them',\n",
              " 'Kim Kardashian is jumping on the hype wave and releasing a fidget spinner. The spinner is a gold money symbol and it says \"daddy,\" which is apt since it\\'s called the Daddy Money Fidget Spinner. It can be yours — with a seven-day shipping delay because these things take time — for the low price of $15, plus $4 for shipping\\n\\nFidget spinners are apparently still a thing. But since I could not give less of a shit about them, I asked my colleague and noted fidget spinner enthusiast, Ashley Carman, what she thought about Kim\\'s latest business endeavor.\\n\\n\"I would never spend $15 on a Kim K spinner,\" says Carman.\\n\\nWell there you have it. Have a nice weekend.',\n",
              " \"10 of London's greatest Victorian projects – 4. The Palace of Westminster… February 6, 2013\\n\\nCommonly thought to be older than it actually is due to its Gothic stylings (although, to be fair, parts of it do date from medieval times), the Palace of Westminster – or, as it's more commonly known, the Houses of Parliament – didn't actually take on much of its current appearance until the latter half of the 19th century.\\n\\nThe need for a new building for parliament arose after 1834 when a fire, caused by the overheating of two underfloor stoves used to incinerate the Exchequer's obsolete tally sticks, tore through the former complex, leaving only some structures from the old palace intact. They included the 11th century Westminster Hall (the largest in Europe when it was built), 14th century Jewel Tower and a chapterhouse, crypt and cloisters, all of which was once attached to the now gone St Stephen's Chapel.\\n\\nWhile King William IV offered the use of Buckingham Palace for Parliament, the idea – along with a host of other options – was rejected as unsuitable. Instead, a competition was held for a new design and after almost 100 entries were considered, architect Charles Barry and his design for a new palace in the perpendicular Gothic style was chosen. Interestingly, while Barry was a classical architect, under the terms of the competition, designs were required to be in a Gothic style, thought to embody conservative values .\\n\\nIncorporating some of the remains of the old palace – including Westminster Hall but not the Jewel Tower which to this day stands alone – the design was based around a series of internal courtyards with the House of Commons and House of Lords located on either side of a central lobby (first known as Octagonal Hall). The design involved reclaiming some land from the Thames so the building's main river-facing facade could be completed.\\n\\nTowers stand at either end of the complex – the Victoria Tower over the Sovereign's Entrance at the southern end of the complex (for many years the tallest square stone tower in the world) and the narrower tower formerly known as the Clock Tower which houses the bell Big Ben, at the northern end – and there is a central Octagonal Tower which stands directly over the Central Lobby. The Clock Tower, incidentally, was renamed the Elizabeth Tower last year in honour of Queen Elizabeth II's Diamond Jubilee (for more on it and Big Ben, see our earlier entries here and here).\\n\\nOther towers include the Speaker's Tower (located at the northern end of the building on the waterfront, this contains a residence for the Speaker), the Chancellor's Tower (located at the southern end, it too contained a residence originally used by the Lord Chancellor) and St Stephen's Tower – located in the middle of the building's west front, it contains the public entrance to the building. Significant other rooms in the palace complex include the Robing Room – where the Queen puts on her ceremonial robes and crown before the State Opening of Parliament – and the Royal Gallery, used for state occasions.\\n\\nThe foundation stone (the building was constructed out of sand-coloured limestone from Yorkshire) was laid in 1840 and construction of the monumental building – which features more than 1,100 rooms and two miles of passageways – wasn't completely finished until the 1870s although most of the work had been completed by 1860 (the year Barry died). The House of Lords first sat in their new chamber in 1847 and the House of Commons in 1852 (it was at this point that Barry was knighted for his work).\\n\\nThe cost, meanwhile, originally estimated at less than £750,000, ended up coming in at more than £2 million.\\n\\nMuch of the interior decoration owes its appearance to the Gothic revivalist Augustus Pugin who designed everything from wallpapers, to floor tiles and furnishings. Pugin also helped Barry with the external appearance but like Barry died before the project was completely finished (in 1852).\\n\\nThe palace was bombed numerous times in World War II – in one raid, the Commons Chamber was destroyed as firefighters opted to save the much older Westminster Hall instead. It was later rebuilt under the direction of Sir Giles Gilbert Scott and completed by 1950. Other aspects of the building have also been restored.\\n\\nA Grade I-listed building classified as a World Heritage Site, Barry's Houses of Parliament remain one of London's most iconic structures. We'll be looking in more detail at some of the building's features in future posts.\\n\\nWHERE: Houses of Parliament (nearest Tube stations are Westminster, St James's Park and Embankment); WHEN: Tours (75 minutes) are run from 9.15am to 4.30pm on Saturdays (also six days a week during summer opening); COST: £15 adults/£10 concessions/£6 children five to 15 years (children under five are free). Prices go up after 1st April – check website for details and to purchase tickets (\",\n",
              " ': This week the Chilean government\\'s promise to protect roughly 10 million acres of land became official, boosting the nation\\'s parklands by 38.5 percent, according to a statement . Read our original story about the move below:\\n\\nLast week, the government of Chile signed an agreement taking possession of a 1-million-acres of private park land put together by a pair of American philanthropists. It also announced it would protect an additional 9 million acres of wildlands as national parks, reports Jonathan Franklin at The Guardian.\\n\\nKris McDivitt Tompkins, former CEO of the clothing company Patagonia and her husband, Doug Tompkins, co-founder of the North Face and Esprit clothing lines, began buying hundreds of thousands of acres in the wild Patagonia region of Chile in the early 1990s, The Guardian\\'s John Vidal reported last year. Their goal, Vidal writes, was to \"buy and restore as much land as they could, improve and protect it, and then return it to people as public, national parks.\"\\n\\nAfter over two decades of work, they acquired 2.2 million acres of land, including the gifted land, Parque Pumalín and Patagonia, which together span roughly 1 million acres and represent the largest land donation from a private entity to a country.\\n\\nBut Chile was not always receptive to the couple. In the beginning of the project, they were accused of being CIA spies, of trying to hobble Chile\\'s economic development and called a national security threat. At one point the government threatened to take their land.\\n\\n\"We were opposed for four years. We were \\'the couple who cut Chile in half,\\'\" McDivitt Tompkins tells Vidal. \"They said we were setting up a nuclear-waste dump or a new Jewish state.\"\\n\\nBut in recent years, the Chilean government has warmed up to the conservation projects, and president Michelle Bachelet was on hand at the border of Pumalin Park to sign the documents authorizing the handover. As Elizabeth Royte at National Geographic reports, Chile hopes to include the new parks in a 1,500-mile tourism route they want to call the Ruta de los Parques, which would link together 17 national parks and offer everything from rainforest hikes and mountaineering to sea kayaking. By some estimates the new parks will bring $270 million into the area and employ 43,000 people.\\n\\nThe new parks make Chile one of Central and South America\\'s most eco-conscious nations. \"That puts Chile right up there with Costa Rica in terms of the percentage of protected lands,\" Yvon Chouinard, founder of the Patagonia clothing company tells Franklin. \"No other human has ever created this many acres of protected wildlands…These are tourist-ready parks with trails and cabins and infrastructure.\"\\n\\nHowever, Doug Tompkins, who died in 2015 in a kayaking accident, will never see the fruits of their labor. \"I wish my husband Doug, whose vision inspired today\\'s historic pledge, were here on this memorable day. Our team and I feel his absence deeply,\" McDivitt Tompkins says in a press release. \"But I know that if Doug were here today, he would speak of national parks being one of the greatest expressions of democracy that a country can realize, preserving the masterpieces of a nation for all of its citizenry.\"\\n\\nThe handover of the Tompkins property will take place incrementally over the next two years.',\n",
              " \"Household fast food names could soon be a thing of the past thanks to the funding of plant-based alternatives from some of the world's biggest investors. The plant-based food scene is changing rapidly, no longer are vegans thought to eat nothing but lettuce and lentils, the plant-based burger revolution has arrived. What's more, big investors are excited about it.\\n\\nRecently, Beyond Meat's burger, otherwise known as 'the burger that bleeds' accomplished something huge when they struck a deal with stores owned by Kroger, that means their burger will be stocked in 605 stores across the US. Beyond have seen investments from some big names including Bill Gates, General Mills and even meat producers Tyson Foods. Tyson's CEO said earlier this year that the future of protein may lie in the meatless market.\\n\\nA similar burger, made by Impossible Foods, who Bill Gates has also invested in, managed to accumulate $75 million worth of funding last month. Alongside Bill Gates, Facebook co-founder Dustin Moskovitz and Asia's second richest man Li Ka-shing were amongst the contributors.\\n\\nImpossible are currently waiting on confirmation from the FDA about their ingredient 'heme', which they were granted a patent for this month. Heme is the key to their 'meat like' burgers and is derived from soy. As yet the FDA are undecided as to whether this product will be considered an allergen, which is currently stopping Impossible from distributing further. However, it seems that they will have a lot of support behind them when they do.\\n\\nTaking it one step further, from individual products to a whole chain of restaurants, By Chloe has taken the US by storm since its first store opened its doors in 2015. The fully plant-based chain which has been described as 'Shake Shack without the meat', is already venturing across the Atlantic to London, where it will open its first European store in Covent Garden later this year. Since opening, the chain has sold over 600,000 vegan burgers, which aren't the only item on their menu. These high figures may account for the whopping $13 million dollars invested in the chain recently to allow them to expand both in the US and overseas.\\n\\nStart-ups like these are seeing an increase in popularity, and it's not surprising. Plant-based foods are much more sustainable than their animal product alternative, something Impossible Foods boast about on their site. The increased number of options allow people who are still keen on the taste of meat, as well as those who want to celebrate vegetables, plenty of things to try without comprising their favourite foods.\\n\\nWith backing from big investors these companies could go from just starting out to fast food giants pretty quickly, and with everything they have to brag about it could mean a sharp decline in some of the world's biggest fast food outlets.\\n\\nUnless, of course, McDonalds want to jump on the plant-based bandwagon?\\n\\nImage credit: Impossible Foods | Beyond Meat | Grub Street | by Chloe\",\n",
              " 'by David E. Petzal - Thursday, June 29, 2017\\n\\nAccording to a poll by the Media Insight Project, only 6 percent of Americans have faith in the news media. Among readers of American Rifleman, that figure is likely even lower. We\\'ve learned that, in all probability, anything we read or hear about guns will be either biased or factually wrong, or both. How come?\\n\\nReason One:\\n\\nLack of accountability. When I broke into the magazine business in 1964, I had some basic rules drummed into my crew-cut head. If you edited a piece, you were responsible for everything in it: spelling, punctuation, facts, everything—especially facts.\\n\\nIf you were wrong, God help you. The least you would get was a serious public tongue-lashing. As a result of this process I can tell you to this day that it\\'s the Smithsonian Institution, not Institute, and that \"prairie\" is not spelled \"prarie.\" A cousin of mine, who worked at one of the big New York City daily newspapers, had exactly the same experience.\\n\\nThis seems to have gone by the wayside. A small example: On Jan. 5, in The New York Times, there was an article on \"ballistics vests.\" What\\'s wrong with this? It\\'s \"ballistic vests.\" \"Ballistics\" is the science of projectile behavior and is a noun, while \"ballistic\" means relating to ballistics, and is an adjective. No one at The Times appears to know the difference. If I had made that mistake, or my cousin had, we would have been screamed at for 10 minutes with no regard for our \"safe space.\"\\n\\nReason Two:\\n\\nPeople in the same profession tend to think alike. Among the news media, the collective wisdom regarding guns runs as follows:\\n\\n1. They believe guns are inherently evil.\\n\\n2. They think gun owners are, at the least, disturbed and, at the worst, dangerous.\\n\\n3. They believe the National Rifle Association has, since its founding in 1871, done nothing worthwhile, has never been right about anything and is nothing more than a shill for the firearm industry.\\n\\n4. They believe the Second Amendment has no relevance in today\\'s United States, and if only we could institute reasonable gun controls there would be no more gun violence.\\n\\n5. It is their opinion that guns in the home lead only to tragedy, and self-protection is a myth.\\n\\nNow, let\\'s assume that you\\'re a student in journalism school, and the subject of guns comes up, and you venture the fact that you own guns, and use them, and that your family has always had guns in the home, and that there\\'s never been an accident, and that you don\\'t even know of any accidents. How do you think that statement would be received?\\n\\nMost likely, you would shortly receive a summons from the dean of students and probably the college psychiatrist to come in and chat, not that there\\'s anything wrong, you understand, but … .\\n\\nOr let\\'s say that you work in a newsroom and the subject of guns used in self-defense comes up and you point out that, every month, you can cite half a dozen or more cases in \"The Armed Citizen\" where someone who had a gun prevented a crime or saved themselves or someone else and, in many instances, did it without firing a shot. Imagine the look you\\'re going to get from the news director. It will not be the kind of look that says your career will prosper here.\\n\\nReason Three:\\n\\nGood old-fashioned ignorance. I got my first exposure to this in the mid-1960s when the armed forces began issuing M16s. The 5.56 mm bullets, we were told by reporters, created terrible wounds because \"they tumbled through the air and hit people like little buzz saws.\"\\n\\n\"Golly gee,\" I said, (or words to that effect), \"that\\'s just not possible. Anything that tumbles through the air isn\\'t going to go where it\\'s aimed. Just look at a football that doesn\\'t spiral.\"\\n\\nBut there it was, and there was more to come.\\n\\nWhen the first Glocks were imported they were denounced as \"all plastic,\" and therefore undetectable at airports. The media, knowing nothing of how guns work, and not understanding such concepts as mass and resistance, printed the nonsense verbatim.\\n\\nWhen the great \"cop-killer-bullet\" brouhaha erupted, the media also neglected to check the facts. If they had, they would have learned that Teflon-coated ammunition was very expensive, made in limited amounts, sold to police agencies only and had never been used to kill a cop.\\n\\nJournalists are ignorant about guns because being knowledgeable about guns requires at least a smattering of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5AyQjxjZH41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code to label the data (webtext=1, gpt-2=0)\n",
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/data/\"\n",
        "\n",
        "def load_split(data_dir, source, split, n=np.inf):\n",
        "    webtext = _load_split(data_dir, 'webtext', split, n=n//2)\n",
        "    gen = _load_split(data_dir, source, split, n=n//2)\n",
        "    texts = webtext+gen\n",
        "    labels = [0]*len(webtext)+[1]*len(gen)\n",
        "    return texts, labels\n",
        "  \n",
        "texts, labels = load_split(data_dir, \"xl-1542M-k40\", \"train\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f22JfB2Fcxj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(texts[250000])\n",
        "# print(labels[250000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjtwqGFjrGx",
        "colab_type": "text"
      },
      "source": [
        "#Dataframes creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-HwVGXGdjUt",
        "colab_type": "code",
        "outputId": "7bc79a7b-b7d4-4e3b-be90-a946458fc15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#create full df (500k docs)\n",
        "df = pd.DataFrame(texts, columns=[\"text\"])\n",
        "df[\"labels\"] = labels\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>These girlfriends deserves a special mention f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LeSean McCoy going through warmups with first ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tom Curran has been called up to England's Ash...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We'll have turkey on the table Thursday but, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The 1945 Sinkings of the Cap Arcona and the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  labels\n",
              "0  These girlfriends deserves a special mention f...       0\n",
              "1  LeSean McCoy going through warmups with first ...       0\n",
              "2  Tom Curran has been called up to England's Ash...       0\n",
              "3  We'll have turkey on the table Thursday but, a...       0\n",
              "4  The 1945 Sinkings of the Cap Arcona and the Th...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eN718P3gGr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create subsets for testing code\n",
        "\n",
        "gpt2_subset500 = df[:500]\n",
        "webtext_subset500 = df[250000:250500]\n",
        "subset_1000 = pd.concat([gpt2_subset500,webtext_subset500]).reset_index()\n",
        "#subset_1000.to_csv(data_dir+\"subset_1k.csv\", index = True)\n",
        "\n",
        "gpt2_subset5k = df[:5000]\n",
        "webtext_subset5k = df[250000:255000]\n",
        "subset_10k = pd.concat([gpt2_subset5k,webtext_subset5k]).reset_index()\n",
        "#subset_10k.to_csv(data_dir+\"subset_10k.csv\", index = True)\n",
        "\n",
        "gpt2_subset25k = df[:25000]\n",
        "webtext_subset25k = df[250000:275000]\n",
        "subset_50k = pd.concat([gpt2_subset25k,webtext_subset25k]).reset_index()\n",
        "#subset_50k.to_csv(data_dir+\"subset_50k.csv\", index = True)\n",
        "\n",
        "gpt2_subset50k = df[:50000]\n",
        "webtext_subset50k = df[250000:300000]\n",
        "subset_100k = pd.concat([gpt2_subset50k,webtext_subset50k]).reset_index()\n",
        "#subset_100k.to_csv(data_dir+\"subset_100k.csv\", index = True)\n",
        "\n",
        "gpt2_subset100k = df[:100000]\n",
        "webtext_subset100k = df[250000:350000]\n",
        "subset_200k = pd.concat([gpt2_subset100k,webtext_subset100k]).reset_index()\n",
        "#subset_200k.to_csv(data_dir+\"subset_200k.csv\", index = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrjpPrcBjiCI",
        "colab_type": "text"
      },
      "source": [
        "#EDA (early data analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UdCCVXAspXz",
        "colab_type": "code",
        "outputId": "68b36fd7-0f19-40cd-89bf-40c2b5aab68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# code to prompt google to give me more ram\n",
        "a = []\n",
        "while(1):\n",
        "    a.append(\"1\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4kJXtDzOPjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3d0fe0ef-09e9-4c85-a19b-a7196ef60300"
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/data/subset_100k.csv\"\n",
        "subset_100k = pd.read_csv(path, index_col=0).reset_index(drop=True)\n",
        "subset_100k.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>These girlfriends deserves a special mention f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>LeSean McCoy going through warmups with first ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tom Curran has been called up to England's Ash...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>We'll have turkey on the table Thursday but, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The 1945 Sinkings of the Cap Arcona and the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               text  labels\n",
              "0      0  These girlfriends deserves a special mention f...       0\n",
              "1      1  LeSean McCoy going through warmups with first ...       0\n",
              "2      2  Tom Curran has been called up to England's Ash...       0\n",
              "3      3  We'll have turkey on the table Thursday but, a...       0\n",
              "4      4  The 1945 Sinkings of the Cap Arcona and the Th...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2UTFae7hP3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "spacy_en = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\",\"textcat\"])\n",
        "\n",
        "# def word_tokenize(text):\n",
        "#     \"\"\"\n",
        "#     Tokenizes English text from a string into a list of strings (tokens)\n",
        "#     \"\"\"\n",
        "#     return [tok.text for tok in spacy_en(text)]\n",
        "\n",
        "# def sent_tokenize(text):\n",
        "#     \"\"\"\n",
        "#     Tokenizes English text from a string into a list of strings (tokens)\n",
        "#     \"\"\"\n",
        "#     return [tok.text for tok in spacy_en(text)]\n",
        "\n",
        "spacy_en.add_pipe(spacy_en.create_pipe('sentencizer')) #adding sentence tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBX_STQck0VG",
        "colab_type": "code",
        "outputId": "e9ed224e-40f2-44c6-ffd4-22533e94e7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "subset_100k.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>These girlfriends deserves a special mention f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>LeSean McCoy going through warmups with first ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tom Curran has been called up to England's Ash...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>We'll have turkey on the table Thursday but, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The 1945 Sinkings of the Cap Arcona and the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               text  labels\n",
              "0      0  These girlfriends deserves a special mention f...       0\n",
              "1      1  LeSean McCoy going through warmups with first ...       0\n",
              "2      2  Tom Curran has been called up to England's Ash...       0\n",
              "3      3  We'll have turkey on the table Thursday but, a...       0\n",
              "4      4  The 1945 Sinkings of the Cap Arcona and the Th...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyNSn0JhP0o",
        "colab_type": "code",
        "outputId": "5558fea6-eb02-46b5-9dba-c1d1ba2232cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "tokenized = spacy_en(subset_100k[\"text\"][0])\n",
        "\n",
        "for tok in tokenized:\n",
        "  print(tok.text)\n",
        "  break\n",
        "\n",
        "for sent in tokenized.sents:\n",
        "  print(sent)\n",
        "  break\n",
        "\n",
        "print(len(tokenized))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These\n",
            "These girlfriends deserves a special mention for going that extra mile, hopefully doesn't set too many guys off on the path towards outrageous demands.\n",
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WaUeooyhPyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eebda2f2-7da6-4139-eea0-baf08a42b599"
      },
      "source": [
        "#takes less than 10 minues\n",
        "start = time.time()\n",
        "subset_100k[\"spacy_doc\"] = subset_100k[\"text\"].map(lambda x: spacy_en(x))\n",
        "end = time.time()\n",
        "print(\"time to tokenize (in secs):\", end-start)\n",
        "# df[\"tokenized_words\"] = df[\"text\"].map(lambda x: word_tokenize(x))\n",
        "# df[\"tokenized_sents\"] = df[\"text\"].map(lambda x: sent_tokenize(x))\n",
        "# tokens_sentences = [word_tokenize(t) for t in sent_tokenize(df[\"text\"][0])]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time to tokenize (in secs): 396.71734619140625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TRUlR2M40x2",
        "colab_type": "code",
        "outputId": "5d42b9ad-c68b-415f-e0f7-65a94572a03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(subset_100k[\"spacy_doc\"][0]))\n",
        "print(len(list(subset_100k[\"spacy_doc\"][0].sents)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4goWWQ740vO",
        "colab_type": "code",
        "outputId": "cb4bdc44-8a13-4064-8839-40609298d356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "subset_100k.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>spacy_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>These girlfriends deserves a special mention f...</td>\n",
              "      <td>0</td>\n",
              "      <td>(These, girlfriends, deserves, a, special, men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>LeSean McCoy going through warmups with first ...</td>\n",
              "      <td>0</td>\n",
              "      <td>(LeSean, McCoy, going, through, warmups, with,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tom Curran has been called up to England's Ash...</td>\n",
              "      <td>0</td>\n",
              "      <td>(Tom, Curran, has, been, called, up, to, Engla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>We'll have turkey on the table Thursday but, a...</td>\n",
              "      <td>0</td>\n",
              "      <td>(We, 'll, have, turkey, on, the, table, Thursd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The 1945 Sinkings of the Cap Arcona and the Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>(The, 1945, Sinkings, of, the, Cap, Arcona, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                          spacy_doc\n",
              "0      0  ...  (These, girlfriends, deserves, a, special, men...\n",
              "1      1  ...  (LeSean, McCoy, going, through, warmups, with,...\n",
              "2      2  ...  (Tom, Curran, has, been, called, up, to, Engla...\n",
              "3      3  ...  (We, 'll, have, turkey, on, the, table, Thursd...\n",
              "4      4  ...  (The, 1945, Sinkings, of, the, Cap, Arcona, an...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13-O90Fn40sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_100k[\"len_words\"] = subset_100k[\"spacy_doc\"].map(lambda x: len(x))\n",
        "\n",
        "subset_100k[\"len_sents\"] = subset_100k[\"spacy_doc\"].map(lambda x: len(list(x.sents)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ae8bd008-5227-4714-d7f0-922650eaed59",
        "id": "bqfjBt1f8xqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#summary statistics for first 50k of 1542M-train-topk40 and 50k of webtext; total 100k docs\n",
        "\n",
        "print(\"average words per doc:\", np.mean(subset_100k[\"len_words\"]))\n",
        "\n",
        "print(\"average sents per doc:\", np.mean(subset_100k[\"len_sents\"]))\n",
        "\n",
        "print(\"max words by doc:\", np.max(subset_100k[\"len_words\"]))\n",
        "\n",
        "print(\"max sents by doc:\", np.max(subset_100k[\"len_sents\"]))\n",
        "\n",
        "print(\"min words by doc:\", np.min(subset_100k[\"len_words\"]))\n",
        "\n",
        "print(\"min sents by doc:\", np.min(subset_100k[\"len_sents\"]))\n",
        "\n",
        "print(\"total vocab:\", len(spacy_en.vocab))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average words per doc: 560.04114\n",
            "average sents per doc: 22.24292\n",
            "max words by doc: 4301\n",
            "max sents by doc: 257\n",
            "min words by doc: 2\n",
            "min sents by doc: 1\n",
            "total vocab: 14303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RggWYSbVWxms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edd9f8c8-fcc3-4f38-e1eb-60ef6d72adea"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG3uMPI3R9mG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "6783b1ab-d537-4b37-b24a-e9443c7b36dd"
      },
      "source": [
        "words = subset_100k.spacy_doc.tolist()\n",
        "print(words[0].text)\n",
        "\n",
        "flat_list = [sublist.text for sublist in words]\n",
        "len(flat_list)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These girlfriends deserves a special mention for going that extra mile, hopefully doesn't set too many guys off on the path towards outrageous demands.\n",
            "\n",
            "1. She knows the severity of man-flu\n",
            "\n",
            "2. All fun and games is all good\n",
            "\n",
            "3. A voucher that says 'I love you'\n",
            "\n",
            "4. When arguments don't drag on forever.\n",
            "\n",
            "5. Providing everything he needs.\n",
            "\n",
            "6. Very understanding\n",
            "\n",
            "7. As awesome a gesture as this is, we are worried about this man's cooking skills.\n",
            "\n",
            "8. Nice cake\n",
            "\n",
            "8. Fair bargaining\n",
            "\n",
            "9. Excellent gift choice\n",
            "\n",
            "10. Very thoughtful\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V1TTF2eVoB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "a2a8736f-6859-4f5f-e759-7729aabb7417"
      },
      "source": [
        "words_set = set()\n",
        "\n",
        "for sent in words:\n",
        "  print(sent)\n",
        "  words_set.add(sent)\n",
        "  break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These girlfriends deserves a special mention for going that extra mile, hopefully doesn't set too many guys off on the path towards outrageous demands.\n",
            "\n",
            "1. She knows the severity of man-flu\n",
            "\n",
            "2. All fun and games is all good\n",
            "\n",
            "3. A voucher that says 'I love you'\n",
            "\n",
            "4. When arguments don't drag on forever.\n",
            "\n",
            "5. Providing everything he needs.\n",
            "\n",
            "6. Very understanding\n",
            "\n",
            "7. As awesome a gesture as this is, we are worried about this man's cooking skills.\n",
            "\n",
            "8. Nice cake\n",
            "\n",
            "8. Fair bargaining\n",
            "\n",
            "9. Excellent gift choice\n",
            "\n",
            "10. Very thoughtful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IRF58NduAPf",
        "colab_type": "code",
        "outputId": "a36889ff-4395-43d1-f02e-136911e24375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "subset_100k.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0   index      100000 non-null  int64 \n",
            " 1   text       100000 non-null  object\n",
            " 2   labels     100000 non-null  int64 \n",
            " 3   spacy_doc  100000 non-null  object\n",
            " 4   len_words  100000 non-null  int64 \n",
            " 5   len_sents  100000 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 4.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jfiyohg62Hv",
        "colab_type": "code",
        "outputId": "e98112c5-6e2c-4d6d-d568-bc3fa65388bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "subset_100k.describe(include=\"all\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>spacy_doc</th>\n",
              "      <th>len_words</th>\n",
              "      <th>len_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>99963</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>DRAFT SCOUT -Ratings Index\\n\\n-Player News Wir...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(HARVARD, 'S, Dani, Rodrik, ,, a, favourite, o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>149999.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>560.041140</td>\n",
              "      <td>22.242920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>125831.203078</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>324.066777</td>\n",
              "      <td>14.769812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24999.750000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>149999.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>543.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>274999.250000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>911.000000</td>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>299999.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4301.000000</td>\n",
              "      <td>257.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                index  ...      len_sents\n",
              "count   100000.000000  ...  100000.000000\n",
              "unique            NaN  ...            NaN\n",
              "top               NaN  ...            NaN\n",
              "freq              NaN  ...            NaN\n",
              "mean    149999.500000  ...      22.242920\n",
              "std     125831.203078  ...      14.769812\n",
              "min          0.000000  ...       1.000000\n",
              "25%      24999.750000  ...      10.000000\n",
              "50%     149999.500000  ...      20.000000\n",
              "75%     274999.250000  ...      33.000000\n",
              "max     299999.000000  ...     257.000000\n",
              "\n",
              "[11 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA_VL-Jm8Ztf",
        "colab_type": "code",
        "outputId": "522c6dee-cd9c-4998-8fc3-345b35102067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "subset_100k[subset_100k[\"labels\"]==0].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>labels</th>\n",
              "      <th>len_words</th>\n",
              "      <th>len_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24999.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>522.453340</td>\n",
              "      <td>21.101920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14433.901067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>324.362722</td>\n",
              "      <td>14.931696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12499.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>24999.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>490.000000</td>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37499.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>878.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>49999.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2211.000000</td>\n",
              "      <td>162.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              index   labels     len_words     len_sents\n",
              "count  50000.000000  50000.0  50000.000000  50000.000000\n",
              "mean   24999.500000      0.0    522.453340     21.101920\n",
              "std    14433.901067      0.0    324.362722     14.931696\n",
              "min        0.000000      0.0     10.000000      1.000000\n",
              "25%    12499.750000      0.0    216.000000      8.000000\n",
              "50%    24999.500000      0.0    490.000000     18.000000\n",
              "75%    37499.250000      0.0    878.000000     32.000000\n",
              "max    49999.000000      0.0   2211.000000    162.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDmsxDxN9gYI",
        "colab_type": "code",
        "outputId": "e49cd8a1-8997-4f5e-e1aa-96c9755c8690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "subset_100k[subset_100k[\"labels\"]==1].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>labels</th>\n",
              "      <th>len_words</th>\n",
              "      <th>len_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>274999.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>597.628940</td>\n",
              "      <td>23.383920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14433.901067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>319.380235</td>\n",
              "      <td>14.516876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>250000.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>262499.750000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>274999.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>287499.250000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>943.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>299999.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4301.000000</td>\n",
              "      <td>257.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               index   labels     len_words     len_sents\n",
              "count   50000.000000  50000.0  50000.000000  50000.000000\n",
              "mean   274999.500000      1.0    597.628940     23.383920\n",
              "std     14433.901067      0.0    319.380235     14.516876\n",
              "min    250000.000000      1.0      2.000000      1.000000\n",
              "25%    262499.750000      1.0    313.000000     12.000000\n",
              "50%    274999.500000      1.0    592.000000     21.000000\n",
              "75%    287499.250000      1.0    943.000000     34.000000\n",
              "max    299999.000000      1.0   4301.000000    257.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6ebf194d-cc17-4724-e122-5feda152aed3",
        "id": "JkFfFP-qF965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(subset_100k[\"spacy_doc\"][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '_bulk_merge',\n",
              " '_py_tokens',\n",
              " '_realloc',\n",
              " '_vector',\n",
              " '_vector_norm',\n",
              " 'cats',\n",
              " 'char_span',\n",
              " 'count_by',\n",
              " 'doc',\n",
              " 'ents',\n",
              " 'extend_tensor',\n",
              " 'from_array',\n",
              " 'from_bytes',\n",
              " 'from_disk',\n",
              " 'get_extension',\n",
              " 'get_lca_matrix',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'is_nered',\n",
              " 'is_parsed',\n",
              " 'is_sentenced',\n",
              " 'is_tagged',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'mem',\n",
              " 'merge',\n",
              " 'noun_chunks',\n",
              " 'noun_chunks_iterator',\n",
              " 'print_tree',\n",
              " 'remove_extension',\n",
              " 'retokenize',\n",
              " 'sentiment',\n",
              " 'sents',\n",
              " 'set_extension',\n",
              " 'similarity',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'to_array',\n",
              " 'to_bytes',\n",
              " 'to_disk',\n",
              " 'to_json',\n",
              " 'to_utf8_array',\n",
              " 'user_data',\n",
              " 'user_hooks',\n",
              " 'user_span_hooks',\n",
              " 'user_token_hooks',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDVpuzxC94zA",
        "colab_type": "code",
        "outputId": "d1fae6a7-0507-4981-a34f-9530bbf93166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qe9JOi2-CWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H08dAVzBWHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}