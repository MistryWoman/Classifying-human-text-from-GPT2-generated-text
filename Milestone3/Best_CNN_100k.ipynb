{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "pvEg-06BHycP",
    "outputId": "4a87c4e1-db17-496e-92a4-8ea149f793e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fGixuwMDwpk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "path = \"/content/drive/My Drive/Colab Notebooks/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d5z9RPU7P4sS",
    "outputId": "ac93bde8-b403-47a9-f6cc-6eda1ff304f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "us_0vewlDzgd",
    "outputId": "68ab8daf-8af2-4bd5-ce40-0c553fa149f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uYh0BzRTDwpu",
    "outputId": "2aea7815-eebb-4454-8514-2f0eac121f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "manual_seed = 77\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHMsTWXgDwp5"
   },
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axp-pCd3Dwp6"
   },
   "outputs": [],
   "source": [
    "# reading in 50k data\n",
    "df = pd.read_csv(path+\"subset_100k.csv\", index_col=0, encoding=\"utf-8\").reset_index(drop=True)\n",
    "# df_shuffled = df.sample(frac=1, random_state=123) #shuffle rows randomly\n",
    "# df_shuffled = df_shuffled.drop(columns=\"index\") #drops index to only keep text and label\n",
    "train, validate, test = np.split(df.sample(frac=1, random_state=123).drop(columns=\"index\"), \n",
    "                                                                          [int(.6*len(df)), int(.8*len(df))])\n",
    "train_texts, train_labels = zip(*train.values) #resulting type is tuples\n",
    "valid_texts, valid_labels = zip(*validate.values)\n",
    "test_texts, test_labels = zip(*test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "2APQb4cd6t-z",
    "outputId": "935656fc-7fb3-4afc-f109-f86261f4e082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 30118, 1: 29882})\n",
      "Counter({1: 10124, 0: 9876})\n",
      "Counter({0: 10006, 1: 9994})\n"
     ]
    }
   ],
   "source": [
    "#check distribution of shuffled data by class (random state 123)\n",
    "\n",
    "print(Counter(train_labels))\n",
    "print(Counter(valid_labels))\n",
    "print(Counter(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Ug6_viDP6t4u",
    "outputId": "fa2a0bf5-8d5b-49f0-8f62-6c95a647d6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "42083  MUMBAI: India's star professional boxer and Ol...       0\n",
      "71825  P.S: This may not seem like something that is ...       1\n",
      "99535  This pattern is available\\n\\nThe pattern is fr...       1\n",
      "                                                    text  labels\n",
      "20737  Ohio Gov. John Kasich is continuing his attack...       0\n",
      "37688  This page has been flagged for a review of its...       0\n",
      "83502  An Ottawa family is speaking out after a photo...       1\n"
     ]
    }
   ],
   "source": [
    "print(train[:3])\n",
    "print(train[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "-jscE4_hGNba",
    "outputId": "31251484-6d11-468d-ee4c-e4967bcdf62d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "75082  A recent study has found that children are mor...       1\n",
      "88345  Greetings Friends,\\n\\n\\nI hope everyone is cel...       1\n",
      "95838  The UESPWiki – Your source for The Elder Scrol...       1\n",
      "                                                    text  labels\n",
      "89728  The Washington Post reports this week that the...       1\n",
      "32245  Climate Change Protesters Canceled March in Co...       0\n",
      "4458   When Canadiens general manager Marc Bergevin s...       0\n"
     ]
    }
   ],
   "source": [
    "print(validate[:3])\n",
    "print(validate[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "yxev-MELGNYX",
    "outputId": "66c3944b-45a2-400c-e919-888617363efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "21563  According to local services' estimates, about ...       0\n",
      "67879  \"I feel extremely lucky that I was at the righ...       1\n",
      "86351  The Department of Homeland Security (DHS) is t...       1\n",
      "                                                    text  labels\n",
      "17730  Just checked into the speaker forum to look fo...       0\n",
      "28030  SHOWCASE ! That Bastard Is Trying To Steal Our...       0\n",
      "15725  Touch Of Malice Check List\\n\\nMausoleum\\n\\n1\\n...       0\n"
     ]
    }
   ],
   "source": [
    "print(test[:3])\n",
    "print(test[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcIpj5u_GNVt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PROuds5qDwqB"
   },
   "outputs": [],
   "source": [
    "#create train, val, test subsets from 50k subset\n",
    "\n",
    "# train.to_csv(path+\"subset_50k_train.csv\", index=False)\n",
    "# validate.to_csv(path+\"subset_50k_valid.csv\", index=False)\n",
    "# test.to_csv(path+\"subset_50k_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "WwCrAhh-DwqT",
    "outputId": "1472a940-4d15-416c-e2d1-b5bfc0f02c94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "20000\n",
      "20000\n",
      "60000\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(validate))\n",
    "print(len(test))\n",
    "\n",
    "print(len(train_texts))\n",
    "print(len(valid_texts))\n",
    "print(len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "RiKTKhVVIaBI",
    "outputId": "44482f53-fe30-4c96-eae5-4b4633c2fbfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                        text  labels\n",
      "0                  We're taking one for the team today in order to make shopping here better.While you wait, read our blog , or check @FinishLine on Instagramand stay up to speed on all things sneakers, style, and sport.       0\n",
      "1              Goal 3: Cut the unemployment rate among young people in half within 3 years. 15 Goals to Rebuild the American Dream\\n\\nThe unemployment rate for young people aged 16 to 24 is above 14 percent.\\n\\nRead More       0\n",
      "2                  Molly Dorozenski, Greenpeace USA joins Thom. Hillary Clinton says that Bernie Sanders is lying when he says that her campaign accepts money from the fossil fuel industry. But what about her Super PACs?       0\n",
      "3                Scientists can now visualize and experiment with structures and dynamics of complex molecular structures (at atomic-level precision), with real-time multi-user collaboration via the cloud\\n\\nJuly 6, 2018       0\n",
      "4  SOLARIUS LYONAR KINGDOMS\\n\\nidle breathing run attack death\\n\\nType: Unit\\n\\nRarity: Legendary\\n\\nSet: Denizens of Shim'Zar\\n\\nCost: 5\\n\\nStats: 3/2\\n\\nEffect:\\n\\nZeal: Draw 2 additional cards at the end of your turn.       0\n",
      "5                  Beasts Of Burgundy - Twelve original new songs from the mind of Jimbo Mathus and the Squirrel Nut Zippers. This is the bands first studio album in 18 years. A return to form... a revival not a reunion.       0\n",
      "6             This program focuses on hands-on, practical experience and culminates with an capstone experience in place of a thesis\\n\\nTo be considered for a $4000 scholarship apply by October 1, 2018\\n\\nNo GRE required       0\n",
      "7                 \"Playing with cats and taking their pictures gives me a lot of joy,\" he told BuzzFeed. \"I decided that my pictures shouldn't look like all other beautiful cat pictures — they must be something special.\"       0\n",
      "8               Milk It Kit\\n\\nMilk It was created by a mom to support moms and the milk they make! It was formed with the idea that pumping milk while working should be less daunting and could be more fun and rewarding.       0\n",
      "9                Pro Tour Amonkhet is now down to just eight players. Take a look at what they brought for this weekend's Standard rounds, and what they will be battling with on Sunday for the title of Pro Tour Champion.       0\n",
      "0    201\n",
      "1    201\n",
      "2    201\n",
      "3    201\n",
      "4    201\n",
      "5    201\n",
      "6    202\n",
      "7    202\n",
      "8    202\n",
      "9    203\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "sub_val = validate[validate.labels==0]\n",
    "\n",
    "# print(validate.text.str.len())\n",
    "\n",
    "# print(validate.text.str.len().sort_values())\n",
    "\n",
    "s = sub_val.text.str.len().sort_values().index\n",
    "df1 = sub_val.reindex(s)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "print(df1.head(10))\n",
    "print(df1.text.str.len().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-Jth99wrSUt"
   },
   "outputs": [],
   "source": [
    "short_string = sub_val[sub_val.text.str.contains(\"Summary Focus of this page: This page discusses our current view of the evidence for a wide range of programs\")].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLth2aZYIZ-F"
   },
   "outputs": [],
   "source": [
    "long_string = sub_val[sub_val.text.str.contains(\"Summary Focus of this page: This page discusses our current view of the evidence for a wide range of programs\")].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AgMjA11IZ7Z"
   },
   "outputs": [],
   "source": [
    "long_string = long_string.to_string()[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDuwLyDmIZ0O"
   },
   "outputs": [],
   "source": [
    "long_string2 = sub_val[sub_val.text.str.contains(\"If you look on a board game shelf, how many games will you see with actions based on collaboration\")].text\n",
    "long_string2 = long_string2.to_string()[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Sc-S656IZw7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGVuozlj-3ga"
   },
   "source": [
    "#Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0v0ZfjMb-3MX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-HXiqTnUDwqY",
    "outputId": "c2827b1f-9c85-4b22-8450-a7245e64dd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100}\n",
      "{'valid_accuracy': 85.79, 'test_accuracy': 87.01}\n"
     ]
    }
   ],
   "source": [
    "#100k subset\n",
    "\n",
    "n_jobs=None\n",
    "verbose=False\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_features=2**21)\n",
    "train_features = vect.fit_transform(train_texts)\n",
    "valid_features = vect.transform(valid_texts)\n",
    "test_features = vect.transform(test_texts)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]} #changed from original code\n",
    "search = GridSearchCV(model, params, cv=5, n_jobs=n_jobs, verbose=verbose)\n",
    "search.fit(sparse.vstack([train_features, valid_features]), train_labels+valid_labels)\n",
    "print(search.best_params_)\n",
    "model = model.set_params(**search.best_params_)\n",
    "model.fit(train_features, train_labels)\n",
    "valid_accuracy = model.score(valid_features, valid_labels)*100.\n",
    "test_accuracy = model.score(test_features, test_labels)*100.\n",
    "data = {\n",
    "    'valid_accuracy':valid_accuracy,\n",
    "    'test_accuracy':test_accuracy\n",
    "}\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time in seconds:\", end-start)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7niM3RYDwqi"
   },
   "source": [
    "# Load and prepare dataset for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPyePrH3Dwqj"
   },
   "outputs": [],
   "source": [
    "# spacy_en = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\",\"textcat\"])\n",
    "# spacy_en.add_pipe(spacy_en.create_pipe('sentencizer')) #adding sentence tokenizer\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm') #changed syntax?\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=True)\n",
    "LABEL = Field(sequential=False, unk_token = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nb-Pc1vtDwqo"
   },
   "outputs": [],
   "source": [
    "#100k subset\n",
    "train, val, test = TabularDataset.splits(\n",
    "               path=path, # the root directory where the data lies\n",
    "               train='subset_100k_train.csv', validation=\"subset_100k_valid.csv\", test=\"subset_100k_test.csv\", # file names\n",
    "               format='csv',\n",
    "               skip_header=True, \n",
    "               fields=[('text', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VBZUYNmrDwqu",
    "outputId": "b1b288d5-e839-4892-f988-4afa8cfc0ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of TEXT: 145549\n",
      "Vocabulary size of LABEL: 2\n"
     ]
    }
   ],
   "source": [
    "#100k subset\n",
    "\n",
    "TEXT.build_vocab(train, min_freq=2)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
    "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "555zXk3JAMyP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOZ4YW9KAMvD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnPFViAHAMsc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45ZqiRdsDwqz"
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits( \n",
    " (train, val), \n",
    " batch_sizes=(64,256),\n",
    " sort_key=lambda x: len(x.text), \n",
    " sort=True,\n",
    " device=device,\n",
    " sort_within_batch=True\n",
    ")\n",
    "\n",
    "test_iter = Iterator(\n",
    "    test,\n",
    "    batch_size=(256),\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWGVVU7dI0UD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLzV6PFZI0Po"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MZNAD9ecDwq5",
    "outputId": "023d45e3-d6dd-4ed1-986b-3e0fc9438b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[    2,    11,    14,  ...,     0,    21, 11695],\n",
      "        [  156,    24,    13,  ...,     8,   115,  2534],\n",
      "        [    6,    13,   266,  ..., 17087,   101,  1805],\n",
      "        ...,\n",
      "        [  152,  9754,  2035,  ...,     1,     1,     1],\n",
      "        [ 1035,     4,  1538,  ...,     1,     1,     1],\n",
      "        [    4,    11,     4,  ...,     1,     1,     1]])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "1\n",
      "tensor([[  6552,    748,  27342,  ...,     34,    192,    628],\n",
      "        [    13,      2, 120582,  ...,   4086,    519,    877],\n",
      "        [     7,  21297,   3091,  ...,  34586,     21,   1141],\n",
      "        ...,\n",
      "        [    18,     14,      0,  ...,      1,      1,      1],\n",
      "        [   666,      4,     31,  ...,      1,      1,      1],\n",
      "        [     4,     11,      4,  ...,      1,      1,      1]])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "2\n",
      "tensor([[ 309,   19,   14,  ..., 1267,  318, 4703],\n",
      "        [   4,   22,   22,  ...,    9,   24,    0],\n",
      "        [   2, 4802, 1676,  ..., 6390,  211,   22],\n",
      "        ...,\n",
      "        [ 268,   23,  231,  ...,    1,    1,    1],\n",
      "        [  61, 2428, 7557,  ...,    1,    1,    1],\n",
      "        [   4,   35,    4,  ...,    1,    1,    1]])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
      "texts: torch.Size([66, 256])\n",
      "labels: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# create a single batch and terminate the loop\n",
    "i = 0\n",
    "for batch in val_iter:\n",
    "    texts = batch.text\n",
    "    labels = batch.label\n",
    "    print(i)\n",
    "    print(texts)\n",
    "    print(labels)\n",
    "    i+=1\n",
    "    if i ==3:\n",
    "      break\n",
    "\n",
    "    #break  #we use first batch as an example.\n",
    "    \n",
    "print('texts:', texts.shape)\n",
    "print('labels:', labels.shape)\n",
    "\n",
    "# texts: [length, batch size]\n",
    "# labels: [batch size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ru0oxXl1Dwq-"
   },
   "source": [
    "# CNN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRB5tHL1Dwq-"
   },
   "outputs": [],
   "source": [
    "# To define a CNN class\n",
    "class CNN_Text(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
    "        '''\n",
    "        vocabulary_size: vocabulary size\n",
    "        embedding_dim: word embedding size\n",
    "        output_size: number of classes in prediction\n",
    "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
    "        region_sizes: height of kernels of convolutional layers\n",
    "        dropout: dropout rate\n",
    "        '''\n",
    "        super(CNN_Text, self).__init__()\n",
    "        # the size of input channel is 1.\n",
    "        Ci = 1\n",
    "        \n",
    "        # word embedding layer\n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim )\n",
    "        \n",
    "        # convolution with kernels\n",
    "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
    "        \n",
    "        # a dropout layer\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input x  [sequence length, batch size]\n",
    "        \n",
    "        input_embeddings = self.embeddings(x)  \n",
    "        # (batch size, word_sequence, embedding_dim) word embedding\n",
    "\n",
    "        input_embeddings = input_embeddings.permute(1,0,2)\n",
    "        input_embeddings = input_embeddings.unsqueeze(1)\n",
    "        #  [batch size, number of channel is one, sequence length, embeeding size]\n",
    "\n",
    "        # convolutional layers\n",
    "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
    "        \n",
    "        # to get the maximum value of filtered tensor\n",
    "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
    "        \n",
    "        concat_list = torch.cat(max_pooling_outputs, 1) # concatenate representations\n",
    "        \n",
    "        drop_output = self.dropout(concat_list)  # add drop layer\n",
    "        \n",
    "        fc1_output = self.fc(drop_output)  # get the fc1 using a fully connected layer\n",
    "        \n",
    "        final_output = F.softmax(fc1_output,dim=1)\n",
    "        \n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jl95C6aODwrD"
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "# the vocabulary size\n",
    "vocabulary_size = len(TEXT.vocab.stoi) \n",
    "\n",
    "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
    "embedding_dim = 300 \n",
    "\n",
    "# region size as 2, 3, and 4\n",
    "kernel_sizes = [2,3,4] \n",
    "\n",
    "# the number of kernel in each region size\n",
    "kernels_num = 32  \n",
    "\n",
    "# The dropout rate is set to be 0.5.\n",
    "dropout = 0.5\n",
    "\n",
    "# The output size of labels.\n",
    "output_size = 2\n",
    "\n",
    "# learning rate is set to be 0.01. CHANGED FROM ORIGINAL\n",
    "lr = 0.0001        \n",
    "\n",
    "# The number of iteration is set to be 5.\n",
    "num_epoch = 5  \n",
    "\n",
    "# employ class CNN_Text and assign to cnn\n",
    "model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZGhseSCDwrI"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "#model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-3nnVOT7DwrN",
    "outputId": "d64ffc69-023a-442e-f5f7-3caed92ec996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 43,929,290 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Og0OdT5w3_Tv",
    "outputId": "1b9ce9ee-b09a-407b-b698-5a7cc19d1e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 43,751,390 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#second run\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cccAFOyUDwrS"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
    "loss_func = nn.CrossEntropyLoss()   # define loss funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxVXTzNCDwrV"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        batch_input, labels = batch.text, batch.label\n",
    "        batch_input = batch_input.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_input)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.cpu().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            batch_input, labels = batch.text, batch.label\n",
    "            batch_input = batch_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(labels.cpu())\n",
    "  \n",
    "    \n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return epoch_loss / len(iterator), accuracy, f1score\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tnMpUT6D5VN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MB38dh_wD5R8",
    "outputId": "d04fd722-4533-44b5-d57b-9e725aec8482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TXWX9rwLDwra",
    "outputId": "6025b333-5398-4eeb-e7bf-0a3bb9f490a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [00:35<11:19, 35.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 35s\n",
      "\n",
      " Epoch [1/20], Train Loss: 0.5524, Validation Loss: 0.5830, Validation Accuracy: 0.6923, Validation F1: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [01:10<10:37, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 34s\n",
      "\n",
      " Epoch [2/20], Train Loss: 0.5374, Validation Loss: 0.5694, Validation Accuracy: 0.7110, Validation F1: 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [01:44<09:57, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 34s\n",
      "\n",
      " Epoch [3/20], Train Loss: 0.5225, Validation Loss: 0.5647, Validation Accuracy: 0.7178, Validation F1: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [02:20<09:24, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 35s\n",
      "\n",
      " Epoch [4/20], Train Loss: 0.5087, Validation Loss: 0.5510, Validation Accuracy: 0.7349, Validation F1: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [02:54<08:45, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 34s\n",
      "\n",
      " Epoch [5/20], Train Loss: 0.4914, Validation Loss: 0.5409, Validation Accuracy: 0.7486, Validation F1: 0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [03:29<08:08, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 34s\n",
      "\n",
      " Epoch [6/20], Train Loss: 0.4751, Validation Loss: 0.5370, Validation Accuracy: 0.7510, Validation F1: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [04:03<07:31, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 34s\n",
      "\n",
      " Epoch [7/20], Train Loss: 0.4582, Validation Loss: 0.5264, Validation Accuracy: 0.7665, Validation F1: 0.7573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [04:39<07:00, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 35s\n",
      "\n",
      " Epoch [8/20], Train Loss: 0.4420, Validation Loss: 0.5210, Validation Accuracy: 0.7730, Validation F1: 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [05:13<06:23, 34.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 34s\n",
      "\n",
      " Epoch [9/20], Train Loss: 0.4255, Validation Loss: 0.5094, Validation Accuracy: 0.7891, Validation F1: 0.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [05:48<05:47, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 34s\n",
      "\n",
      " Epoch [10/20], Train Loss: 0.4107, Validation Loss: 0.5108, Validation Accuracy: 0.7844, Validation F1: 0.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [06:23<05:12, 34.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 34s\n",
      "\n",
      " Epoch [11/20], Train Loss: 0.3977, Validation Loss: 0.5058, Validation Accuracy: 0.7910, Validation F1: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [06:58<04:39, 34.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 35s\n",
      "\n",
      " Epoch [12/20], Train Loss: 0.3860, Validation Loss: 0.4991, Validation Accuracy: 0.7984, Validation F1: 0.7935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [07:33<04:03, 34.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 34s\n",
      "\n",
      " Epoch [13/20], Train Loss: 0.3766, Validation Loss: 0.4941, Validation Accuracy: 0.8038, Validation F1: 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [08:07<03:28, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 34s\n",
      "\n",
      " Epoch [14/20], Train Loss: 0.3687, Validation Loss: 0.4896, Validation Accuracy: 0.8073, Validation F1: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 15/20 [08:43<02:54, 34.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 35s\n",
      "\n",
      " Epoch [15/20], Train Loss: 0.3604, Validation Loss: 0.4922, Validation Accuracy: 0.8049, Validation F1: 0.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 16/20 [09:17<02:19, 34.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 34s\n",
      "\n",
      " Epoch [16/20], Train Loss: 0.3542, Validation Loss: 0.4877, Validation Accuracy: 0.8105, Validation F1: 0.8072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|████████▌ | 17/20 [09:52<01:44, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 34s\n",
      "\n",
      " Epoch [17/20], Train Loss: 0.3497, Validation Loss: 0.4854, Validation Accuracy: 0.8125, Validation F1: 0.8095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 18/20 [10:26<01:09, 34.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 34s\n",
      "\n",
      " Epoch [18/20], Train Loss: 0.3446, Validation Loss: 0.4850, Validation Accuracy: 0.8123, Validation F1: 0.8093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████▌| 19/20 [11:02<00:34, 34.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 35s\n",
      "\n",
      " Epoch [19/20], Train Loss: 0.3409, Validation Loss: 0.4890, Validation Accuracy: 0.8077, Validation F1: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [11:36<00:00, 34.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 34s\n",
      "\n",
      " Epoch [20/20], Train Loss: 0.3383, Validation Loss: 0.4885, Validation Accuracy: 0.8085, Validation F1: 0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 100k subset\n",
    "MAX_EPOCH = 20\n",
    "total_step = len(train_iter)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iter, optimizer, loss_func)  \n",
    "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, loss_func)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Create checkpoint at end of each epoch\n",
    "    state_dict_model = model.state_dict() \n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state_dict_model,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "    #torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_cnn/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, \n",
    "                                                                MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WapTzwTGj1O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PwLGWmQFDwrj",
    "outputId": "c4abf3ed-258e-4583-b959-da1ac5c8b7a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch:   5%|▌         | 1/20 [00:50<16:08, 50.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 33s\n",
      "\n",
      " Epoch [1/20], Train Loss: 0.6163, Validation Loss: 0.6705, Validation Accuracy: 0.5815, Validation F1: 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  10%|█         | 2/20 [01:38<14:59, 49.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 32s\n",
      "\n",
      " Epoch [2/20], Train Loss: 0.5944, Validation Loss: 0.6342, Validation Accuracy: 0.6254, Validation F1: 0.5769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  15%|█▌        | 3/20 [02:26<13:58, 49.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 32s\n",
      "\n",
      " Epoch [3/20], Train Loss: 0.5799, Validation Loss: 0.6162, Validation Accuracy: 0.6469, Validation F1: 0.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|██        | 4/20 [03:01<12:00, 45.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 33s\n",
      "\n",
      " Epoch [4/20], Train Loss: 0.5663, Validation Loss: 0.5998, Validation Accuracy: 0.6696, Validation F1: 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  25%|██▌       | 5/20 [03:37<10:34, 42.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 33s\n",
      "\n",
      " Epoch [5/20], Train Loss: 0.5524, Validation Loss: 0.5829, Validation Accuracy: 0.6925, Validation F1: 0.6715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  30%|███       | 6/20 [04:12<09:20, 40.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 32s\n",
      "\n",
      " Epoch [6/20], Train Loss: 0.5373, Validation Loss: 0.5693, Validation Accuracy: 0.7116, Validation F1: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  35%|███▌      | 7/20 [04:46<08:19, 38.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 32s\n",
      "\n",
      " Epoch [7/20], Train Loss: 0.5225, Validation Loss: 0.5645, Validation Accuracy: 0.7179, Validation F1: 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  40%|████      | 8/20 [05:22<07:31, 37.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 33s\n",
      "\n",
      " Epoch [8/20], Train Loss: 0.5087, Validation Loss: 0.5510, Validation Accuracy: 0.7359, Validation F1: 0.7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  45%|████▌     | 9/20 [05:57<06:44, 36.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 32s\n",
      "\n",
      " Epoch [9/20], Train Loss: 0.4916, Validation Loss: 0.5406, Validation Accuracy: 0.7491, Validation F1: 0.7379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  50%|█████     | 10/20 [06:31<06:01, 36.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 32s\n",
      "\n",
      " Epoch [10/20], Train Loss: 0.4752, Validation Loss: 0.5365, Validation Accuracy: 0.7535, Validation F1: 0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  55%|█████▌    | 11/20 [07:06<05:21, 35.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 32s\n",
      "\n",
      " Epoch [11/20], Train Loss: 0.4583, Validation Loss: 0.5265, Validation Accuracy: 0.7668, Validation F1: 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  60%|██████    | 12/20 [07:42<04:46, 35.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 33s\n",
      "\n",
      " Epoch [12/20], Train Loss: 0.4421, Validation Loss: 0.5209, Validation Accuracy: 0.7725, Validation F1: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  65%|██████▌   | 13/20 [08:17<04:08, 35.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 32s\n",
      "\n",
      " Epoch [13/20], Train Loss: 0.4256, Validation Loss: 0.5094, Validation Accuracy: 0.7883, Validation F1: 0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  70%|███████   | 14/20 [08:52<03:31, 35.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 32s\n",
      "\n",
      " Epoch [14/20], Train Loss: 0.4107, Validation Loss: 0.5098, Validation Accuracy: 0.7857, Validation F1: 0.7788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  75%|███████▌  | 15/20 [09:26<02:55, 35.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 32s\n",
      "\n",
      " Epoch [15/20], Train Loss: 0.3977, Validation Loss: 0.5059, Validation Accuracy: 0.7905, Validation F1: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  80%|████████  | 16/20 [10:02<02:21, 35.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 34s\n",
      "\n",
      " Epoch [16/20], Train Loss: 0.3861, Validation Loss: 0.4993, Validation Accuracy: 0.7977, Validation F1: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  85%|████████▌ | 17/20 [10:37<01:45, 35.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 32s\n",
      "\n",
      " Epoch [17/20], Train Loss: 0.3767, Validation Loss: 0.4947, Validation Accuracy: 0.8040, Validation F1: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  90%|█████████ | 18/20 [11:12<01:10, 35.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 32s\n",
      "\n",
      " Epoch [18/20], Train Loss: 0.3686, Validation Loss: 0.4898, Validation Accuracy: 0.8079, Validation F1: 0.8043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  95%|█████████▌| 19/20 [11:48<00:35, 35.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 33s\n",
      "\n",
      " Epoch [19/20], Train Loss: 0.3605, Validation Loss: 0.4912, Validation Accuracy: 0.8063, Validation F1: 0.8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|██████████| 20/20 [12:23<00:00, 37.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 32s\n",
      "\n",
      " Epoch [20/20], Train Loss: 0.3543, Validation Loss: 0.4874, Validation Accuracy: 0.8098, Validation F1: 0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#second run -- this time saving model\n",
    "\n",
    "MAX_EPOCH = 20\n",
    "total_step = len(train_iter)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iter, optimizer, loss_func)  \n",
    "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, loss_func)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Create checkpoint at end of each epoch\n",
    "    state_dict_model = model.state_dict() \n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state_dict_model,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "    torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt/CNN_\"+str(epoch+1)+\".pt\")\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, \n",
    "                                                                MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZ4shD5mDwrm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-59zk_Q797F"
   },
   "source": [
    "#Best model Evaluations and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVmEAjjEnRVK"
   },
   "outputs": [],
   "source": [
    "#functions I need\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def evaluate_confusion_matrix(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            batch_input, labels = batch.text, batch.label\n",
    "            batch_input = batch_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(labels.cpu())\n",
    "  \n",
    "    confuse_matrix = sklearn.metrics.confusion_matrix(all_label,all_pred, labels=[1, 0])\n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return epoch_loss / len(iterator), accuracy, f1score, confuse_matrix\n",
    "\n",
    "\n",
    "#credit this function to https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-v1tr-NlnRSf"
   },
   "outputs": [],
   "source": [
    "#100k subset\n",
    "# train, val, test = TabularDataset.splits(\n",
    "#                path=path, # the root directory where the data lies\n",
    "#                train='subset_100k_train.csv', validation=\"subset_100k_valid.csv\", test=\"subset_100k_test.csv\", # file names\n",
    "#                format='csv',\n",
    "#                skip_header=True, \n",
    "#                fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "# TEXT.build_vocab(train, min_freq=2)\n",
    "# LABEL.build_vocab(train)\n",
    "\n",
    "# print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
    "# print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))\n",
    "\n",
    "# train_iter, val_iter = BucketIterator.splits( \n",
    "#  (train, val), \n",
    "#  batch_sizes=(64,256),\n",
    "#  sort_key=lambda x: len(x.text), \n",
    "#  sort=True,\n",
    "#  device=device,\n",
    "#  sort_within_batch=True\n",
    "# )\n",
    "\n",
    "# test_iter = Iterator(\n",
    "#     test,\n",
    "#     batch_size=(256),\n",
    "#     sort_key=lambda x: len(x.text),\n",
    "#     sort=False,\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "lF-nfyBeDwrr",
    "outputId": "b47454bc-2df3-4131-e5f0-bc3b017c9147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Text(\n",
       "  (embeddings): Embedding(145549, 300)\n",
       "  (convolution_layers): ModuleList(\n",
       "    (0): Conv2d(1, 32, kernel_size=(2, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 32, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 32, kernel_size=(4, 300), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=96, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "# the vocabulary size\n",
    "vocabulary_size = len(TEXT.vocab.stoi) \n",
    "\n",
    "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
    "embedding_dim = 300 \n",
    "\n",
    "# region size as 2, 3, and 4\n",
    "kernel_sizes = [2,3,4] \n",
    "\n",
    "# the number of kernel in each region size\n",
    "kernels_num = 32  \n",
    "\n",
    "# The dropout rate is set to be 0.5.\n",
    "dropout = 0.5\n",
    "\n",
    "# The output size of labels.\n",
    "output_size = 2\n",
    "\n",
    "# learning rate is set to be 0.01. CHANGED FROM ORIGINAL\n",
    "lr = 0.0001        \n",
    "\n",
    "\n",
    "# employ class CNN_Text and assign to cnn\n",
    "best_model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)\n",
    "best_model.apply(init_weights)\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "best_model.load_state_dict(torch.load('./drive/My Drive/Colab Notebooks/ckpt/CNN_20.pt')['state_dict'])\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "lS0ZfyA9DmhC",
    "outputId": "d668c71b-022e-48ff-c2a5-a8e6f1f3ee9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041122713913283\n",
      "Confusion matrix, without normalization\n",
      "[[9306  688]\n",
      " [3170 6836]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, acc, fscore, cm = evaluate_confusion_matrix(best_model, test_iter, loss_func)\n",
    "print(fscore)\n",
    "plot_confusion_matrix(cm, (\"Webtext\", \"GPT-2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXo1KbmUFcaj"
   },
   "source": [
    "My evaluation:\n",
    "- Overall, the best CNN model did well on the test set, predicting about 80% of the data correctly (16142 out of 20000). In terms of error, the model had a tougher time correclty detecting GPT-2 generated text. Actually, 82% of the wrong predictions were categorizing GPT-2 text as Webtext (3170/3858). I suspect two reasons for this result: (1) there is a subset of GPT-2 data that is (coincidentally?) very well generated and mimics human text, or (2) the shorter lengthed GPT-2 text is harder to categorize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FQC4Q4pBDmXT"
   },
   "outputs": [],
   "source": [
    "test_string1 = \"Scientists can now visualize and experiment with structures and dynamics of complex molecular structures (at atomic-level precision), with real-time multi-user collaboration via the cloud\\n\\nJuly 6, 2018\"\n",
    "\n",
    "test_string2 = \"Pro Tour Amonkhet is now down to just eight players. Take a look at what they brought for this weekend's Standard rounds, and what they will be battling with on Sunday for the title of Pro Tour Champion.\"\n",
    "\n",
    "test_string3 =  long_string\n",
    "\n",
    "test_string4 = long_string2\n",
    "\n",
    "test_string5 = \"Scientists can now visualize and experiment with structures and the dynamics of complex molecular makeup (at atomic-level precision), with real-time multi-user collaboration via the cloud\\n\\nJuly 6, 2018\"\n",
    "\n",
    "test_string6 = \"Summary Focus of this page: This page discusses our current view of the evidence for a wide range of programs and interventions that aim to improve education in developing countries. These include demand-side interventions that lower the cost of schooling or increase its (perceived) returns, provision of school inputs, pedagogy interventions, and governance reforms. We focus mainly on interventions aimed at improving primary and secondary education but consider vocational training interventions briefly. We have not yet completed a report on early childhood (pre-school) interventions. On this page, we focus on evidence from experimental study designs.\"\n",
    "\n",
    "test_string7 = \"If you look on a board game shelf, how many games will you see with actions based on collaboration, stewardship, generosity, and gratitude? Most likely, you'll find mechanics like attacking, stealing, and backstabbing. Indigenous communities looking to facilitate intergenerational gameplay are thus hard-pressed to find options that reinforce their teachings. In response, communities are developing their own games for passing on teachings in many forms. As espoused by game designer Brenda Romero, the mechanic is the message. And the messages in the board game The Gift of Food—inspired by collaborative game development with Indigenous communities working with the Northwest Indian College—produce culturally responsive gameplay, meaning gameplay that is drawn from and that uplifts the cultures involved.\\n\\nThe Gift of Food is an ideal example of how culturally responsive board games can function as important pathways for passing on Indigenous ways of knowing\"\n",
    "\n",
    "test_strings_list = [test_string1, test_string2, test_string3, test_string4, test_string5, test_string6, test_string7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "id": "WozCvOEdjbFA",
    "outputId": "111e9829-963a-46e4-e629-61032bc0a64d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2_string_1 is 38 words long.\n",
      "The text: \"Scientists can now visualize and experiment with structures and dynamics of complex molecular structures (at atomic-level precision), with real-time multi-user collaboration via the cloud\n",
      "\n",
      "July 6, 2018\"\n",
      "The prediction for GPT-2_string_1 is 1 and the model was 0.6872% confident.\n",
      "----------\n",
      "GPT-2_string_2 is 42 words long.\n",
      "The text: \"Pro Tour Amonkhet is now down to just eight players. Take a look at what they brought for this weekend's Standard rounds, and what they will be battling with on Sunday for the title of Pro Tour Champion.\"\n",
      "The prediction for GPT-2_string_2 is 1 and the model was 0.8143% confident.\n",
      "----------\n",
      "GPT-2_string_3 is 169 words long.\n",
      "The text: \"Summary Focus of this page: This page discusses our current view of the evidence for a wide range of programs and interventions that aim to improve education in developing countries. These include demand-side interventions that lower the cost of schooling or increase its (perceived) returns, provision of school inputs, pedagogy interventions, and governance reforms. We focus mainly on interventions aimed at improving primary and secondary education but consider vocational training interventions briefly. We have not yet completed a report on early childhood (pre-school) interventions. On this page, we focus on evidence from experimental study designs.\\n\\nThis page discusses our current view of the evidence for a wide range of programs and interventions that aim to improve education in developing countries. These include demand-side interventions that lower the cost of schooling or increase its (perceived) returns, provision of school inputs, pedagogy interventions, and governance re...\"\n",
      "The prediction for GPT-2_string_3 is 0 and the model was 0.8338% confident.\n",
      "----------\n",
      "GPT-2_string_4 is 169 words long.\n",
      "The text: \"If you look on a board game shelf, how many games will you see with actions based on collaboration, stewardship, generosity, and gratitude? Most likely, you'll find mechanics like attacking, stealing, and backstabbing. Indigenous communities looking to facilitate intergenerational gameplay are thus hard-pressed to find options that reinforce their teachings. In response, communities are developing their own games for passing on teachings in many forms. As espoused by game designer Brenda Romero, the mechanic is the message. And the messages in the board game The Gift of Food—inspired by collaborative game development with Indigenous communities working with the Northwest Indian College—produce culturally responsive gameplay, meaning gameplay that is drawn from and that uplifts the cultures involved.\\n\\nThe Gift of Food is an ideal example of how culturally responsive board games can function as important pathways for passing on Indigenous ways of knowing, as learning and reinforcin...\"\n",
      "The prediction for GPT-2_string_4 is 0 and the model was 0.9623% confident.\n",
      "----------\n",
      "GPT-2_string_5 is 39 words long.\n",
      "The text: \"Scientists can now visualize and experiment with structures and the dynamics of complex molecular makeup (at atomic-level precision), with real-time multi-user collaboration via the cloud\n",
      "\n",
      "July 6, 2018\"\n",
      "The prediction for GPT-2_string_5 is 1 and the model was 0.7422% confident.\n",
      "----------\n",
      "GPT-2_string_6 is 113 words long.\n",
      "The text: \"Summary Focus of this page: This page discusses our current view of the evidence for a wide range of programs and interventions that aim to improve education in developing countries. These include demand-side interventions that lower the cost of schooling or increase its (perceived) returns, provision of school inputs, pedagogy interventions, and governance reforms. We focus mainly on interventions aimed at improving primary and secondary education but consider vocational training interventions briefly. We have not yet completed a report on early childhood (pre-school) interventions. On this page, we focus on evidence from experimental study designs.\"\n",
      "The prediction for GPT-2_string_6 is 1 and the model was 0.6829% confident.\n",
      "----------\n",
      "GPT-2_string_7 is 28 words long.\n",
      "The text: \"If you look on a board game shelf, how many games will you see with actions based on collaboration, stewardship, generosity, and gratitude?\"\n",
      "The prediction for GPT-2_string_7 is 1 and the model was 0.6283% confident.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for each in test_strings_list:\n",
    "  preprocessed = TEXT.preprocess(each)\n",
    "  tensored = TEXT.process([preprocessed], device=device)\n",
    "  best_model.eval()\n",
    "  output = best_model(tensored)\n",
    "  probabilities, predicted = torch.max(output.cpu().data, 1)\n",
    "  print(f\"GPT-2_string_{i} is {len(preprocessed)} words long.\")\n",
    "  print(f'The text: \"{each}\"')\n",
    "  print(f\"The prediction for GPT-2_string_{i} is {predicted.item()} and the model was {round(probabilities.item(), 4)}% confident.\")\n",
    "  print(\"----------\")\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4RYv4sbn-ou"
   },
   "source": [
    "My analysis:\n",
    "* As previous works have pointed out, short sentences are harder to detect. This CNN model found the same, making wrong predictions for the shorter sentences. Interestingly, the model was not as confident with its prediction for string_1 though.\n",
    "* String_1 analysis: I managed to increase the model's prediction probability to 74% by making the sentence a bit more fluent by adding one \"the\" and removing a repeated word, replacing the second \"structure\" with \"makeup\". I also experimented with the punctuations and but found that they did not make a difference in the model's probability. I also removed the date during my trial-and-error and found it made no difference to the model. The biggest gain in probability comes from removing the repeated word. \n",
    "* String_4 analysis: having established that repeated words appear to be an indicator for synthetic text detection for a CNN model, this string actually has and a few repeated sentences. Hence, the model confidently predicted it is GPT-2 generated. I removed the repetition in string_6, which also shortened the sentence, and the model then made the wrong prediction, thinking the string_6 is human-generated.\n",
    "* String_5 analysis: I think the model correctly predicted this document because it lacks coherence. Even though the document is more or less grammatically correct, the topics include boardgames, Indigenous communities, cultural values, a specific board game that is oddlyl named. I tried using this example to see how short it needed to be for the model to make a wrong prediction. I simply deleted one sentence at a time to see how the CNN responded and I was surprised to find I had to truncate the document to one sentence (i.e., 28 words long) in order to fool the model. There is definitely some features in this document that makes the model very confident it is synthetically produced.\n",
    "* From my personal analysis as a linguist, I actually agree with the CNN model's predictions, even the wrong ones. When I read the short sentences (string_1 and string_2), even though I think that string_1 is worded a little awkwardly, overall I would be unsure if it was synthetic text or not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxzlnHyYjbCi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KStK0kkWjbAE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvrhixIsja9O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLH_d4j3Fal4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yFOEAEQFaif"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoJQqN2CDwrt"
   },
   "outputs": [],
   "source": [
    "def evaluate_confusion_matrix(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            batch_input, labels = batch.text, batch.label\n",
    "            batch_input = batch_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(labels.cpu())\n",
    "  \n",
    "    confuse_matrix = sklearn.metrics.confusion_matrix(all_label,all_pred, labels=[1, 0])\n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return epoch_loss / len(iterator), accuracy, f1score, confuse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MTuO8LNV-N5P",
    "outputId": "b6bffb2a-987c-47af-90ea-4c08e79c6a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9412  712]\n",
      " [3092 6784]]\n"
     ]
    }
   ],
   "source": [
    "loss, acc, fscore, cm = evaluate_confusion_matrix(model, val_iter, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHrUKQZb_PGV"
   },
   "outputs": [],
   "source": [
    "#credit this function to https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "MAch7eJFAoym",
    "outputId": "f768374e-fd5b-45ea-bd49-53bb39e80ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9412  712]\n",
      " [3092 6784]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, (\"Webtext\", \"GPT-2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9O2hib2A1N0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Best_CNN_100k.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
